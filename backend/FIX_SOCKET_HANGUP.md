# üîß Gi·∫£i Ph√°p Kh·∫Øc Ph·ª•c L·ªói "Socket Hang Up" - Backend

## üî¥ Nguy√™n Nh√¢n Ch√≠nh

1. **Uvicorn ch·∫°y v·ªõi c·∫•u h√¨nh m·∫∑c ƒë·ªãnh:**
   - Ch·ªâ 1 worker (single-threaded)
   - Kh√¥ng c√≥ timeout settings
   - Kh√¥ng c√≥ connection limits
   - Kh√¥ng c√≥ rate limiting

2. **Supabase Database Connection:**
   - Connection pool c√≥ th·ªÉ c·∫°n ki·ªát
   - Kh√¥ng c√≥ connection pooling configuration
   - Queries c√≥ th·ªÉ ch·∫°y qu√° l√¢u

3. **Nhi·ªÅu requests ƒë·ªìng th·ªùi:**
   - 3 users g·ª≠i tin nh·∫Øn c√πng l√∫c
   - Backend kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c concurrent requests

## ‚úÖ Gi·∫£i Ph√°p

### Solution 1: T·ªëi ∆Øu Uvicorn Configuration

**File: `backend/main.py`**

Thay ƒë·ªïi ph·∫ßn cu·ªëi:

```python
if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",  # Thay ƒë·ªïi t·ª´ "localhost"
        port=8000,
        reload=True,
        log_level="info",
        # Th√™m c√°c settings sau:
        workers=2,  # TƒÉng s·ªë workers (n·∫øu c√≥ ƒë·ªß RAM)
        timeout_keep_alive=75,  # TƒÉng timeout
        limit_concurrency=100,  # Gi·ªõi h·∫°n concurrent connections
        limit_max_requests=1000,  # Restart worker sau 1000 requests (tr√°nh memory leak)
        backlog=2048,  # TƒÉng backlog queue
    )
```

**L∆∞u √Ω:** N·∫øu ch·∫°y tr√™n Windows, `workers` kh√¥ng ho·∫°t ƒë·ªông. Ch·ªâ d√πng tr√™n Linux/Mac.

### Solution 2: T·∫°o File Ch·∫°y Production

**File: `backend/run_production.py`**

```python
"""
Production server runner v·ªõi c·∫•u h√¨nh t·ªëi ∆∞u
"""
import uvicorn
import multiprocessing

if __name__ == "__main__":
    # T√≠nh s·ªë workers d·ª±a tr√™n CPU cores
    workers = max(2, multiprocessing.cpu_count())
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        workers=workers,  # S·ªë workers = s·ªë CPU cores
        log_level="info",
        timeout_keep_alive=75,
        limit_concurrency=200,
        limit_max_requests=1000,
        backlog=2048,
        access_log=True,
    )
```

### Solution 3: Th√™m Rate Limiting Middleware

**File: `backend/middleware/rate_limit.py`** (T·∫°o m·ªõi)

```python
"""
Rate Limiting Middleware
"""
from fastapi import Request, HTTPException
from starlette.middleware.base import BaseHTTPMiddleware
from collections import defaultdict
import time
from typing import Dict, Tuple

class RateLimitMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, requests_per_minute: int = 60):
        super().__init__(app)
        self.requests_per_minute = requests_per_minute
        self.requests: Dict[str, list] = defaultdict(list)
    
    async def dispatch(self, request: Request, call_next):
        # L·∫•y IP address
        client_ip = request.client.host if request.client else "unknown"
        
        # Ki·ªÉm tra rate limit
        now = time.time()
        minute_ago = now - 60
        
        # L·ªçc requests trong 1 ph√∫t qua
        self.requests[client_ip] = [
            req_time for req_time in self.requests[client_ip]
            if req_time > minute_ago
        ]
        
        # Ki·ªÉm tra s·ªë requests
        if len(self.requests[client_ip]) >= self.requests_per_minute:
            raise HTTPException(
                status_code=429,
                detail="Qu√° nhi·ªÅu requests. Vui l√≤ng th·ª≠ l·∫°i sau."
            )
        
        # Th√™m request hi·ªán t·∫°i
        self.requests[client_ip].append(now)
        
        # X·ª≠ l√Ω request
        response = await call_next(request)
        return response
```

**Th√™m v√†o `main.py`:**

```python
from middleware.rate_limit import RateLimitMiddleware

# Th√™m sau CORS middleware
app.add_middleware(
    RateLimitMiddleware,
    requests_per_minute=100  # 100 requests/ph√∫t/user
)
```

### Solution 4: T·ªëi ∆Øu Database Connection (N·∫øu d√πng Supabase Client)

**File: `backend/database.py`** (T·∫°o m·ªõi n·∫øu ch∆∞a c√≥)

```python
"""
Database connection pool configuration
"""
from supabase import create_client, Client
from config import settings
import asyncio
from typing import Optional

# Global Supabase client v·ªõi connection pooling
_supabase_client: Optional[Client] = None

def get_supabase_client() -> Client:
    """Get or create Supabase client with connection pooling"""
    global _supabase_client
    
    if _supabase_client is None:
        _supabase_client = create_client(
            settings.SUPABASE_URL,
            settings.SUPABASE_SERVICE_KEY,
            options={
                "db": {
                    "schema": "public",
                },
                "auth": {
                    "auto_refresh_token": True,
                    "persist_session": False,  # Kh√¥ng persist session ƒë·ªÉ tr√°nh memory leak
                },
                "global": {
                    "headers": {
                        "x-client-info": "financial-management-backend",
                    },
                },
            }
        )
    
    return _supabase_client
```

### Solution 5: Th√™m Request Timeout Middleware

**File: `backend/middleware/timeout.py`** (T·∫°o m·ªõi)

```python
"""
Request Timeout Middleware
"""
from fastapi import Request, HTTPException
from starlette.middleware.base import BaseHTTPMiddleware
import asyncio

class TimeoutMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, timeout: int = 30):
        super().__init__(app)
        self.timeout = timeout
    
    async def dispatch(self, request: Request, call_next):
        try:
            # T·∫°o timeout task
            response = await asyncio.wait_for(
                call_next(request),
                timeout=self.timeout
            )
            return response
        except asyncio.TimeoutError:
            raise HTTPException(
                status_code=504,
                detail=f"Request timeout sau {self.timeout} gi√¢y"
            )
```

**Th√™m v√†o `main.py`:**

```python
from middleware.timeout import TimeoutMiddleware

app.add_middleware(TimeoutMiddleware, timeout=30)  # 30 seconds timeout
```

## üöÄ C√°ch √Åp D·ª•ng

### B∆∞·ªõc 1: C·∫≠p nh·∫≠t `main.py`

```python
# Thay ƒë·ªïi ph·∫ßn cu·ªëi c·ªßa main.py
if __name__ == "__main__":
    import sys
    import os
    
    # Ki·ªÉm tra m√¥i tr∆∞·ªùng
    is_production = os.getenv("ENVIRONMENT") == "production"
    
    if is_production:
        # Production: Ch·∫°y v·ªõi workers
        uvicorn.run(
            "main:app",
            host="0.0.0.0",
            port=8000,
            workers=2,  # TƒÉng s·ªë workers
            log_level="info",
            timeout_keep_alive=75,
            limit_concurrency=100,
            limit_max_requests=1000,
        )
    else:
        # Development: Ch·∫°y v·ªõi reload
        uvicorn.run(
            "main:app",
            host="0.0.0.0",
            port=8000,
            reload=True,
            log_level="debug",
            timeout_keep_alive=75,
        )
```

### B∆∞·ªõc 2: T·∫°o c√°c middleware files

1. T·∫°o `backend/middleware/rate_limit.py`
2. T·∫°o `backend/middleware/timeout.py`
3. Th√™m v√†o `main.py`

### B∆∞·ªõc 3: Test

```bash
# Restart backend
cd backend
python main.py

# Test v·ªõi nhi·ªÅu requests
# M·ªü 3 browser windows v√† g·ª≠i tin nh·∫Øn c√πng l√∫c
```

## üìä Monitoring

### Ki·ªÉm tra s·ªë connections:

```python
# Th√™m endpoint ƒë·ªÉ check health
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "workers": 1,  # S·∫Ω thay ƒë·ªïi n·∫øu d√πng workers
    }
```

### Ki·ªÉm tra logs:

```bash
# Xem logs realtime
tail -f backend/logs/app.log | grep -i "error\|timeout\|connection"
```

## ‚ö†Ô∏è L∆∞u √ù

1. **Windows:** Kh√¥ng h·ªó tr·ª£ `workers` trong uvicorn. Ch·ªâ d√πng tr√™n Linux/Mac ho·∫∑c production server.

2. **Memory:** TƒÉng workers s·∫Ω tƒÉng memory usage. Monitor memory usage.

3. **Database:** Supabase c√≥ gi·ªõi h·∫°n connections. Kh√¥ng tƒÉng qu√° nhi·ªÅu workers n·∫øu kh√¥ng c·∫ßn.

4. **Testing:** Test t·ª´ng solution m·ªôt, kh√¥ng √°p d·ª•ng t·∫•t c·∫£ c√πng l√∫c.

