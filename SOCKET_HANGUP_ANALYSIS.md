# üîç Ph√¢n T√≠ch L·ªói "Socket Hang Up" v√† 500 Internal Server Error

## ‚ùå L·ªói Hi·ªán T·∫°i

```
Request URL: http://localhost:3000/api/tasks/project/{project_id}/comments
Status Code: 500 Internal Server Error
Error: socket hang up / ECONNRESET
```

## üîç Nguy√™n Nh√¢n Th∆∞·ªùng G·∫∑p

### 1. **Backend Server Timeout** ‚è±Ô∏è
- **Nguy√™n nh√¢n:** Query qu√° l√¢u, v∆∞·ª£t qu√° timeout c·ªßa server
- **D·∫•u hi·ªáu:** Connection b·ªã ƒë·ª©t gi·ªØa ch·ª´ng (ECONNRESET)
- **Gi·∫£i ph√°p:** 
  - TƒÉng timeout settings
  - T·ªëi ∆∞u query (ƒë√£ l√†m - batch processing)
  - Th√™m pagination

### 2. **Backend Server Crash/Out of Memory** üí•
- **Nguy√™n nh√¢n:** 
  - Query tr·∫£ v·ªÅ qu√° nhi·ªÅu data ‚Üí Out of Memory
  - Exception kh√¥ng ƒë∆∞·ª£c catch ‚Üí Server crash
- **D·∫•u hi·ªáu:** Server kh√¥ng ph·∫£n h·ªìi, connection reset
- **Gi·∫£i ph√°p:**
  - Limit s·ªë l∆∞·ª£ng records tr·∫£ v·ªÅ
  - Th√™m try-catch to√†n di·ªán
  - Monitor memory usage

### 3. **Database Connection Timeout** üóÑÔ∏è
- **Nguy√™n nh√¢n:** 
  - Supabase connection pool exhausted
  - Query qu√° ph·ª©c t·∫°p
  - Database overload
- **D·∫•u hi·ªáu:** Timeout khi query database
- **Gi·∫£i ph√°p:**
  - Connection pooling
  - Query optimization
  - Retry logic

### 4. **Network Issues** üåê
- **Nguy√™n nh√¢n:**
  - Proxy timeout (Next.js ‚Üí Backend)
  - Keep-alive timeout qu√° ng·∫Øn
- **D·∫•u hi·ªáu:** Connection reset gi·ªØa frontend v√† backend
- **Gi·∫£i ph√°p:**
  - TƒÉng proxy timeout
  - TƒÉng keep-alive timeout

### 5. **Backend Process Killed** ‚ö†Ô∏è
- **Nguy√™n nh√¢n:**
  - OOM Killer (Out of Memory)
  - Process manager restart
  - System resource limit
- **D·∫•u hi·ªáu:** Server ƒë·ªôt ng·ªôt kh√¥ng ph·∫£n h·ªìi
- **Gi·∫£i ph√°p:**
  - Monitor memory
  - Optimize code
  - Increase resource limits

## ‚úÖ Gi·∫£i Ph√°p ƒê√£ √Åp D·ª•ng

### 1. Batch Processing (ƒê√£ l√†m)
```python
# Chia query th√†nh batches 100 tasks/batch
BATCH_SIZE = 100
for i in range(0, len(task_ids), BATCH_SIZE):
    batch_task_ids = task_ids[i:i + BATCH_SIZE]
    # Query t·ª´ng batch
```

### 2. Error Handling (ƒê√£ l√†m)
```python
try:
    # Query batch
except Exception as batch_error:
    logger.warning(f"Error fetching comments for batch: {str(batch_error)}")
    continue  # Continue v·ªõi batch ti·∫øp theo
```

## üîß Gi·∫£i Ph√°p B·ªï Sung C·∫ßn L√†m

### 1. Th√™m Timeout v√† Limit cho Endpoint

```python
@router.get("/project/{project_id}/comments", response_model=List[TaskComment])
async def get_project_comments(
    project_id: str,
    limit: int = Query(1000, ge=1, le=5000),  # Limit s·ªë comments
    current_user: User = Depends(get_current_user)
):
    # ... existing code ...
    
    # Limit s·ªë comments tr·∫£ v·ªÅ
    if len(all_comments) > limit:
        all_comments = all_comments[-limit:]  # L·∫•y limit comments m·ªõi nh·∫•t
```

### 2. Th√™m Pagination

```python
@router.get("/project/{project_id}/comments", response_model=List[TaskComment])
async def get_project_comments(
    project_id: str,
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=500),
    current_user: User = Depends(get_current_user)
):
    # ... fetch comments ...
    
    # Paginate
    return enriched_comments[skip:skip+limit]
```

### 3. T·ªëi ∆Øu Query - Ch·ªâ L·∫•y Comments M·ªõi Nh·∫•t

```python
# Thay v√¨ l·∫•y t·∫•t c·∫£ comments, ch·ªâ l·∫•y comments g·∫ßn ƒë√¢y
comments_result = supabase.table("task_comments").select("""
    *,
    users:user_id(id, full_name),
    employees:employee_id(id, first_name, last_name)
""").in_("task_id", batch_task_ids)\
    .order("created_at", desc=True)\
    .limit(1000)\
    .execute()  # Limit 1000 comments m·ªõi nh·∫•t
```

### 4. Th√™m Connection Retry

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
async def fetch_comments_with_retry(supabase, task_ids):
    # Query v·ªõi retry logic
    pass
```

### 5. TƒÉng Timeout trong Next.js Config

```typescript
// next.config.ts
async rewrites() {
  return [
    {
      source: '/api/:path*',
      destination: `${apiUrl}/api/:path*`,
      // Th√™m timeout
    }
  ]
}
```

### 6. Th√™m Response Streaming (Cho Large Data)

```python
from fastapi.responses import StreamingResponse
import json

@router.get("/project/{project_id}/comments")
async def get_project_comments_stream(
    project_id: str,
    current_user: User = Depends(get_current_user)
):
    async def generate():
        # Stream comments t·ª´ng batch
        for batch in batches:
            yield json.dumps(batch) + "\n"
    
    return StreamingResponse(generate(), media_type="application/json")
```

## üéØ Khuy·∫øn Ngh·ªã Ngay L·∫≠p T·ª©c

### Priority 1: Th√™m Limit v√† Timeout
1. Th√™m `limit` parameter ƒë·ªÉ gi·ªõi h·∫°n s·ªë comments
2. Th√™m timeout cho Supabase queries
3. TƒÉng timeout trong Next.js proxy config

### Priority 2: Optimize Query
1. Ch·ªâ l·∫•y comments m·ªõi nh·∫•t (last 1000)
2. Th√™m pagination
3. Cache k·∫øt qu·∫£ n·∫øu c√≥ th·ªÉ

### Priority 3: Monitoring
1. Th√™m logging chi ti·∫øt
2. Monitor memory usage
3. Track query performance

## üìä Checklist Debug

- [ ] Ki·ªÉm tra backend logs ƒë·ªÉ xem l·ªói c·ª• th·ªÉ
- [ ] Ki·ªÉm tra xem backend c√≥ ƒëang ch·∫°y kh√¥ng
- [ ] Ki·ªÉm tra memory usage c·ªßa backend
- [ ] Ki·ªÉm tra Supabase connection pool
- [ ] Test v·ªõi project c√≥ √≠t tasks/comments tr∆∞·ªõc
- [ ] Ki·ªÉm tra network latency gi·ªØa frontend v√† backend

## üîç C√°ch Debug

### 1. Ki·ªÉm tra Backend Logs
```bash
# Xem logs c·ªßa backend
tail -f backend/logs/app.log
# ho·∫∑c
python backend/main.py  # Xem console output
```

### 2. Test API Tr·ª±c Ti·∫øp
```bash
curl -X GET "http://localhost:8000/api/tasks/project/6bf71318-f57f-405f-b137-f6770c99cd01/comments" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

### 3. Ki·ªÉm tra Database Query
```python
# Th√™m logging v√†o endpoint
logger.info(f"Fetching {len(task_ids)} tasks, estimated {estimated_comments} comments")
```

---

**L∆∞u √Ω:** L·ªói "socket hang up" th∆∞·ªùng x·∫£y ra khi:
- Backend x·ª≠ l√Ω qu√° l√¢u (> 30-60s)
- Backend crash ho·∫∑c out of memory
- Network timeout
- Database connection timeout

**Gi·∫£i ph√°p t·ªët nh·∫•t:** Th√™m limit, pagination, v√† optimize query!
